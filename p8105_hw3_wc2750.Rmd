---
title: "p8105_hw3_wc2750"
author: "Weixi Chen"
date: "10/9/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

## Problem 1
Load instacart dataset
```{r}
library(p8105.datasets)
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?
```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

Let's make a plot
```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x= aisle, y = n)) +
  geom_point() +
  labs(y = "number of items", title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), plot.title = element_text(hjust = 0.5))
```

Let's make a table
```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank <4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Apple vs ice cream
```{r message = FALSE}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2
### Part 1
Import and tidy accel_data
```{r message = FALSE}
accel_df = read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    cols = starts_with("activity_"),
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>%
  # include a weekday vs weekend variable
  mutate (
    weekday_vs_weekend = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday")
  ) %>%
  # encode data with reasonable variable classes
  mutate(
    week = as.integer(week),
    day_id = as.integer(day_id),
    day = ordered(as.factor(day), levels=c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
    minute = as.integer(minute),
    weekday_vs_weekend = as.factor(weekday_vs_weekend)
  ) %>%
  # arrange in reasonable order and organize variables
  arrange(week,day,minute) %>%
  relocate(week, day_id, day, weekday_vs_weekend)

# preview accel_df
accel_df
```

The accel_df has `r nrow(accel_df)` rows and `r ncol(accel_df)` columns. The observation data is collected from `r max(accel_df$week)` weeks and `r max(accel_df$day_id)` days. The day variable indicates the day of the week. The added weekday_vs_weekend variable specifies whether that day is weekday or weekend. The minute variable ranges from `r min(accel_df$minute)` to `r max(accel_df$minute)`. The activity_counts variable indicates the activity counts for each minute.

### Part 2
Total acitivity over the day
```{r message = FALSE}
# table for aggregate daily activity counts
accel_df %>%
  group_by(day_id) %>%
  summarize(daily_activity = sum(activity_count))
```

```{r message = FALSE}
# table more easier to read
accel_df %>%
  group_by(week,day) %>%
  summarize(daily_activity = sum(activity_count)) %>%
  pivot_wider(
    names_from = day,
    values_from = daily_activity
  )
```

Visualize the trends
```{r message = FALSE}
accel_df %>%
  group_by(week,day) %>%
  summarize(daily_activity = sum(activity_count)) %>%
  ggplot(aes(x = day, y = daily_activity, group = week, color = week)) +
  geom_point() +
  geom_line() +
  labs(x = "day of the week", y = "daily acitivity", title = "Daily activity of each day of a week among the 5-week observation", caption = "data collected on a 63 year-old male with BMI 25") +
  theme(plot.title = element_text(size = 10, hjust = 0.5))
```

For week 1,2, and 5, the activity count of the observed subject is gradually increasing through the weekdays. For week 3, the subject has the maximum activity on Monday and then keeps a stable amount of activity in the following days. For week 4, the activity count keeps stable from Monday to Wednesday but decreases after Wednesday. For week 1, 2, and 3, the activity count during weekends is close to the count on the same week's Friday. For week 4 and 5, the subject has nearly zero amount of activity on Saturday and relatively lower amount on Sunday.

### Part 3
Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week
```{r message = FALSE}
accel_df %>%
  group_by(day, minute) %>%
  summarize(weekday_activity = sum(activity_count)) %>%
  ggplot(aes(x = minute, y = weekday_activity, color = day)) +
  geom_point(alpha = .3, size = .5) +
  geom_smooth(size = .5) +
  labs(x= "hours", y= "activity count", title = "24-hour activity time courses for each day", caption = "data collected on a 63 year-old male with BMI 25", color = "day of the week") +
  scale_x_continuous(
    breaks = c(seq(0, 1440, by = 60)),
    labels = c(seq(0, 24, by = 1))) +
  theme(plot.title = element_text(hjust = 0.5))
```

The observed subject might sleep around 11:30PM and get up around 5AM. He has relatively higher amount of activity from 10AM to 12PM on Sunday and from 8PM to 10PM on Friday. For the rest of the time, his activity amount keeps stable.

## Problem 3
Load data
```{r}
library(p8105.datasets)
data("ny_noaa")
```

### Part 1
Clean ny_noaa dataset
```{r}
noaa_df =
  ny_noaa %>%
  # create separate variables for year, month, and day
  separate(date, c("year", "month", "day"), convert = TRUE) %>%
  # ensure observations for temperature, precipitation, and snowfall are given in reasonable units
  mutate(
    prcp = prcp / 10,
    tmax = as.numeric(tmax),
    tmax = tmax / 10,
    tmin = as.numeric(tmin),
    tmin = tmin / 10
  )
```

Commonly observed values in snowfall
```{r message = FALSE}
noaa_df %>%
  drop_na(snow) %>%
  group_by(snow) %>%
  summarize(snow_count = n()) %>%
  mutate(snow_rank = min_rank(desc(snow_count))) %>%
  filter(snow_rank < 4) %>%
  arrange(snow_rank)
```

The top 3 common snowfalls are 0, 25, and 13. The large count of zero snowfall indicates there is no snowfall for most of the time.

### Part 2
Make a two-panel plot showing the average max temperature in January and in July in each station across years
```{r message = FALSE, warning = FALSE}
noaa_df %>%
  filter(month == 1 | month == 7) %>%
  group_by(id, year, month) %>%
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = mean_tmax, color = id)) +
  geom_point(size = .8) +
  facet_grid(.~month, labeller = as_labeller(c(`1` = "January", `7` = "July"))) +
  labs(y = "temperature (°C)", title = "Average max temperature in January and in July in each station across years", caption = "data accessed from the NOAA National Climatic Data Center, \n http://doi.org/10.7289/V5D21VHZ, on August 15, 2017") +
  theme(legend.position = "none", plot.title = element_text(size = 12, hjust = 0.5), panel.spacing = unit(2, "lines"))
```

The average max temperature detected by each station across years in January ranges from -10 °C to 10 °C, which is lower than that in July that ranges from 20 °C to 35 °C. There are some outliers reflected on the plots. For example, the average max temperature detected by certain stations in January, 1982 and in July, 1988 are extremely low.

### Part 3
Make a plot showing tmax vs tmin for the full dataset
```{r warning = FALSE}
# tmax vs tmin for the full dataset
tmax_vs_tmin_plot = 
  noaa_df %>%
  ggplot(aes(x = tmax, y = tmin)) + 
  geom_hex() +
  labs(x = "maximum temperature (°C)", y = "minimum temperature (°C)", title = "tmax vs tmin for the full dataset") +
  theme(plot.title = element_text(size = 10, hjust = 0.5), legend.position = "right")
```

Make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year
```{r warning = FALSE}
snowfall_plot =
  noaa_df %>%
  filter(snow>0 & snow<100) %>%
  ggplot(aes(x = year, y = snow, group = year, color = year)) +
  geom_violin(aes(fill = year), alpha = .5) +
  stat_summary(fun = "median", color = "yellow", size = .1) +
  labs(y = "snowfall (mm)", title = "Distribution of snowfall by year", caption = "data accessed from the NOAA National Climatic Data Center, \n http://doi.org/10.7289/V5D21VHZ, on August 15, 2017") +
  theme(plot.title = element_text(size = 10, hjust = 0.5), legend.position = "none")
```

Make a two-panel plot combining the above two plots
```{r warning = FALSE}
# patchwork
tmax_vs_tmin_plot + snowfall_plot
```

The noaa_df shows the weather data collected by the weather stations at New York State. This dataset includes `r nrow(noaa_df)` rows and `r ncol(noaa_df)` columns. The observation year ranges from `r min(noaa_df$year)` to `r max(noaa_df$year)`. 

Within the years of observation, the precipitation ranges from `r min(noaa_df$prcp, na.rm = TRUE)`mm to `r max(noaa_df$prcp, na.rm = TRUE)`mm, the snowfall ranges from `r min(noaa_df$snow, na.rm = TRUE)`mm to `r max(noaa_df$snow, na.rm = TRUE)`mm, the snow depth ranges from `r min(noaa_df$snwd, na.rm = TRUE)`mm to `r max(noaa_df$snwd, na.rm = TRUE)`mm, the maximum temperature ranges from `r min(noaa_df$tmax, na.rm = TRUE)`°C to `r max(noaa_df$tmax, na.rm = TRUE)`°C, and the minimum temperature ranges from `r min(noaa_df$tmin, na.rm = TRUE)`°C to `r max(noaa_df$tmin, na.rm = TRUE)`°C.

There are large number of missing data which may lead to inaccurate analysis. The precipitation variable has `r sum(is.na(noaa_df$prcp))` missing data. The snowfall has `r sum(is.na(noaa_df$snow))` missing data. The snow depth variable has `r sum(is.na(noaa_df$snwd))` missing data. The maximum temperature variable has `r sum(is.na(noaa_df$tmax))` missing data. The minimum temperature variable has `r sum(is.na(noaa_df$tmin))` missing data.
